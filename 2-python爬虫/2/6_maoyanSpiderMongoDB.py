"""
    çŒ«çœ¼ç”µå½±top100æ•°æ®æŠ“å– - å­˜å…¥ CSVæ–‡ä»¶
    æ€è·¯ï¼š
        1. åœ¨ __init__ä¸­åˆ›å»ºç›¸å…³è¿å¯¹è±¡
        2. åœ¨ save_html() ä¸­æŠŠæŠ“å–çš„æ•°æ®å¤„ç†ä¸ºå­—å…¸ï¼Œç„¶åå­˜å…¥mongodbæ•°æ®åº“
"""

import random
import re
import time
import pymongo
import requests


class MAoyanSpider:
    def __init__(self):
        self.url = 'https://www.maoyan.com/board/4?offset={}'
        self.headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',
            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',
            'Accept-Language': 'zh-CN,zh;q=0.8,zh-TW;q=0.7,zh-HK;q=0.5,en-US;q=0.3,en;q=0.2',
            'Accept-Encoding': 'gzip, deflate',
            'Connection': 'keep-alive',
            'Upgrade-Insecure-Requests': '1',
        }

        # åˆ›å»º MongoDB è¿æ¥ - ä¿®æ­£åçš„ä»£ç 
        self.conn = pymongo.MongoClient('localhost', 27017)
        self.db = self.conn['filmdb']
        self.collection = self.db['filmset']

        # åˆ é™¤è¿™è¡Œï¼ŒMongoDB æ²¡æœ‰ cursor() æ–¹æ³•
        # self.cursor = self.db.cursor()

    def create_table(self):
        """MongoDB ä¸éœ€è¦åˆ›å»ºè¡¨ï¼Œä½†å¯ä»¥åˆ›å»ºç´¢å¼•"""
        try:
            # åˆ›å»ºç´¢å¼•ï¼ˆMongoDB çš„ç­‰ä»·æ“ä½œï¼‰
            self.collection.create_index([("title", pymongo.TEXT)])
            self.collection.create_index([("star", 1)])
            self.collection.create_index([("time", 1)])
            print("âœ… MongoDB é›†åˆå’Œç´¢å¼•å·²å°±ç»ª")
        except Exception as e:
            print(f"âŒ åˆ›å»ºç´¢å¼•å¤±è´¥: {e}")

    def get_html(self, url):
        """è·å–å“åº”å†…å®¹"""
        try:
            print(f"ğŸŒ æ­£åœ¨è¯·æ±‚: {url}")
            response = requests.get(url, headers=self.headers, timeout=10)
            print(f"ğŸ“Š å“åº”çŠ¶æ€ç : {response.status_code}")

            if response.status_code == 200:
                response.encoding = 'utf-8'
                html = response.text
                # ä¿å­˜HTMLå†…å®¹åˆ°æ–‡ä»¶ç”¨äºè°ƒè¯•
                with open(f'maoyan_page_{url.split("=")[-1]}.html', 'w', encoding='utf-8') as f:
                    f.write(html)
                print(f"ğŸ’¾ é¡µé¢å†…å®¹å·²ä¿å­˜ï¼Œé•¿åº¦: {len(html)} å­—ç¬¦")
                self.parse_html(html)
            else:
                print(f"âŒ è¯·æ±‚å¤±è´¥ï¼ŒçŠ¶æ€ç : {response.status_code}")

        except Exception as e:
            print(f"âŒ è¯·æ±‚å¤±è´¥: {e}")

    def parse_html(self, html):
        """è§£ææå–å‡½æ•°"""
        print("ğŸ” å¼€å§‹è§£æHTML...")

        # æ­£åˆ™è¡¨è¾¾å¼æ¨¡å¼
        pattern = '<div class="movie-item-info">.*?title="(.*?)".*?<p class="star">(.*?)</p>.*?<p class="releasetime">(.*?)</p>'

        try:
            regex = re.compile(pattern, re.S)
            r_list = regex.findall(html)

            if r_list:
                print(f"âœ… æ‰¾åˆ° {len(r_list)} æ¡ç”µå½±æ•°æ®")
                self.save_html(r_list)
            else:
                print("âŒ æ²¡æœ‰æ‰¾åˆ°ç”µå½±æ•°æ®ï¼Œè¯·æ£€æŸ¥æ­£åˆ™è¡¨è¾¾å¼")
                # æ‰“å°éƒ¨åˆ†HTMLå†…å®¹ç”¨äºè°ƒè¯•
                print("ğŸ“‹ HTMLç‰‡æ®µ:", html[:1000])

        except Exception as e:
            print(f"âŒ è§£æå¤±è´¥: {e}")

    def save_html(self, r_list):
        """ä¿å­˜æ•°æ®åˆ° MongoDB"""
        try:
            for r in r_list:
                item = {
                    'title': r[0].strip(),
                    'star': r[1].strip(),
                    'releasetime': r[2].strip(),
                    'crawl_time': time.strftime('%Y-%m-%d %H:%M:%S')
                }

                # æ’å…¥æ•°æ®åˆ° MongoDB
                result = self.collection.insert_one(item)
                print(f"âœ… ä¿å­˜æˆåŠŸ: {item['title']} (ID: {result.inserted_id})")

        except Exception as e:
            print(f"âŒ ä¿å­˜å¤±è´¥: {e}")

    def run(self):
        """è¿è¡Œçˆ¬è™«"""
        print("ğŸš€ å¼€å§‹çˆ¬å–çŒ«çœ¼ç”µå½±æ•°æ®...")
        self.create_table()

        # çˆ¬å–å¤šé¡µæ•°æ®
        for offset in range(0, 100, 10):  # 0, 10, 20, ..., 90
            url = self.url.format(offset)
            self.get_html(url)
            time.sleep(random.uniform(1, 3))  # éšæœºå»¶è¿Ÿï¼Œé¿å…è¢«å°

        print("ğŸ‰ çˆ¬å–å®Œæˆï¼")

        # æ˜¾ç¤ºçˆ¬å–çš„æ•°æ®ç»Ÿè®¡
        count = self.collection.count_documents({})
        print(f"ğŸ“Š æ€»å…±çˆ¬å– {count} æ¡ç”µå½±æ•°æ®")


# è¿è¡Œçˆ¬è™«
if __name__ == '__main__':
    spider = MAoyanSpider()
    spider.run()


